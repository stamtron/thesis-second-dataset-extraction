{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data_and_augmentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (14,7)\n",
    "font = {'family' : 'DejaVu Sans',  'weight' : 'normal',  'size'  : 20}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = get_tensor_transform('Kinetics', True)\n",
    "train_spat_transform = get_spatial_transform(2)\n",
    "train_temp_transform = get_temporal_transform(30)\n",
    "valid_spat_transform = get_spatial_transform(0)\n",
    "valid_temp_transform = va.TemporalFit(size=30)\n",
    "\n",
    "root_dir = '/media/scratch/astamoulakatos/centre_Ch2/'\n",
    "df = pd.read_csv('../important_csvs/more_balanced_dataset/more_balanced_stratified.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(frac=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df.number_of_frames>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_df(df, 50, True, False, False)\n",
    "class_image_paths, end_idx, idx_label= get_indices(df_train, root_dir)\n",
    "#train_loader = get_loader(16, 64, end_idx, class_image_paths, train_temp_transform, train_spat_transform, tensor_transform, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idx_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_image_paths), len(end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_label.count('exp'), idx_label.count('exp_and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_list = []\n",
    "for i in range(len(end_idx)-1):\n",
    "    seq_length_list.append((end_idx[i+1]-end_idx[i]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seq_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths = torch.tensor(seq_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths, end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my new sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_new_Sampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, end_idx):\n",
    "        end_idx = end_idx[:-1]\n",
    "        indices = end_idx\n",
    "        seq_length_list = []\n",
    "        for i in range(len(end_idx)-1):\n",
    "            seq_length_list.append((end_idx[i+1]-end_idx[i]).item())\n",
    "        seq_lengths = torch.tensor(seq_length_list)        \n",
    "        self.indices = indices\n",
    "        self.seq_lengths = seq_lengths\n",
    "        \n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(0)\n",
    "        indices = self.indices[torch.randperm(len(self.indices))]\n",
    "        seq_lengths = self.seq_lengths[torch.randperm(len(self.seq_lengths))]\n",
    "        indices = indices.tolist()\n",
    "        seq_lengths = seq_lengths.tolist()\n",
    "        index_plus_seq = zip(indices, seq_lengths)\n",
    "        #random.shuffle(list(index_plus_seq))\n",
    "        return iter(index_plus_seq)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = My_new_Sampler(end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_different_seq(Dataset):\n",
    "    def __init__(self, image_paths, temp_transform, spat_transform, tensor_transform, length, lstm=False, oned = False, augment = False, multi = 1): #csv_file, \n",
    "        self.image_paths = image_paths\n",
    "        #self.seq_length = seq_length\n",
    "        self.temp_transform = temp_transform\n",
    "        self.spat_transform = spat_transform\n",
    "        self.tensor_transform = tensor_transform\n",
    "        self.length = length\n",
    "        self.lstm = lstm\n",
    "        self.oned = oned\n",
    "        self.augment = augment\n",
    "        self.multi = multi\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        start = index[0]\n",
    "        end = index[0] + index[1]\n",
    "        print('Getting images from {} to {}'.format(start, end))\n",
    "        indices = list(range(start, end))\n",
    "        images = []\n",
    "        #tr = self.transform\n",
    "        for i in indices:\n",
    "            image_path = self.image_paths[i][0]\n",
    "            image = Image.open(image_path)\n",
    "            images.append(image)\n",
    "        x = images\n",
    "        if not self.oned:\n",
    "            x = self.temp_transform(x)\n",
    "        if self.augment:\n",
    "            x = self.spat_transform(x)\n",
    "        x = self.tensor_transform(x)\n",
    "        y = torch.tensor([self.image_paths[start][self.multi]], dtype=torch.long)\n",
    "        y = y.squeeze(dim=0)\n",
    "        y = y.float()\n",
    "        #print(y.shape)\n",
    "        if self.lstm:\n",
    "            x = x.permute(1,0,2,3)\n",
    "        if self.oned:\n",
    "            x = x.squeeze(dim=1)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset_different_seq(\n",
    "        image_paths = class_image_paths,\n",
    "        temp_transform = valid_temp_transform,\n",
    "        spat_transform = valid_spat_transform,\n",
    "        tensor_transform = tensor_transform,\n",
    "        length = len(sampler),\n",
    "        lstm = False,\n",
    "        oned = False,\n",
    "        augment = True,\n",
    "        multi = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = 100,\n",
    "        sampler = sampler,\n",
    "        drop_last = True,\n",
    "        num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idx_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_loader, 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Shuffle of both seq_lengths and indices in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx = end_idx[torch.randperm(len(end_idx))]\n",
    "seq_lengths = seq_lengths[torch.randperm(len(seq_lengths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "label_indices = []\n",
    "for i in range(len(end_idx) - 1):\n",
    "    start = end_idx[i] #+ 40 #so that we dont use the first 40 frames, especially in 2d resnet!\n",
    "    start_label = idx_label[i]\n",
    "    end = end_idx[i + 1] - seq_length #- 20 #so that we dont use the last 20 frames\n",
    "    if start > end:\n",
    "        pass\n",
    "    else:\n",
    "        label_indices.extend(repeat(start_label,end-start))\n",
    "        indices.append(torch.arange(start, end))\n",
    "indices = torch.cat(indices)\n",
    "#self.indices = indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indices.count('exp'), label_indices.count('exp_and'), label_indices.count('bur'), label_indices.count('exp_fj'), label_indices.count('exp_fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_indices = pd.DataFrame({'label_indices':label_indices})\n",
    "df_label_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_indices.label_indices.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indices[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = indices[torch.randperm(len(indices))]\n",
    "t = iter(indices.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbalanced_sampler_3 import MultilabelBalancedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in class_image_paths:\n",
    "    labels.append(i[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1): \n",
    "  \n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "    # print list \n",
    "    for x in unique_list: \n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = MultilabelBalancedRandomSampler(\n",
    "    labels, indices, class_choice=\"least_sampled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(\n",
    "        image_paths = class_image_paths,\n",
    "        seq_length = 100,\n",
    "        temp_transform = valid_temp_transform,\n",
    "        spat_transform = valid_spat_transform,\n",
    "        tensor_transform = tensor_transform,\n",
    "        length = len(train_sampler),\n",
    "        lstm = False,\n",
    "        oned = False,\n",
    "        augment = True,\n",
    "        multi = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = 10,\n",
    "        sampler = train_sampler,\n",
    "        drop_last = True,\n",
    "        num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = get_df(df, 100, False, True, False)\n",
    "class_image_paths, end_idx = get_indices(df_valid, root_dir)\n",
    "valid_loader = get_loader(100, 10, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, False, False, False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ = torch.zeros(5); sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"================ Training phase ===============\")\n",
    "sum_ = torch.zeros(5)\n",
    "for x, y in train_loader:\n",
    "    print(\"Label counts per class:\")\n",
    "    sum_ = sum_ + y.sum(axis=0)\n",
    "    #sum_ = y.sum(axis=0)\n",
    "    print(sum_) \n",
    "    print(\"Difference between min and max\")\n",
    "    print(max(sum_) - min(sum_))\n",
    "    print(\"\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_loader, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=============== Validation phase ==============\")\n",
    "for x, y in valid_loader:\n",
    "    print(\"Label counts per class:\")\n",
    "    sum_ = y.sum(axis=0)\n",
    "    print(sum_)\n",
    "    print(\"Difference between min and max\")\n",
    "    print(max(sum_) - min(sum_))\n",
    "    print(\"\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(valid_loader, 10 , False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
