{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comparison of Calibration of Classifiers\n",
    "\n",
    "\n",
    "Well calibrated classifiers are probabilistic classifiers for which the output\n",
    "of the predict_proba method can be directly interpreted as a confidence level.\n",
    "For instance a well calibrated (binary) classifier should classify the samples\n",
    "such that among the samples to which it gave a predict_proba value close to\n",
    "0.8, approx. 80% actually belong to the positive class.\n",
    "\n",
    "LogisticRegression returns well calibrated predictions as it directly\n",
    "optimizes log-loss. In contrast, the other methods return biased probabilities,\n",
    "with different biases per method:\n",
    "\n",
    "* GaussianNaiveBayes tends to push probabilities to 0 or 1 (note the counts in\n",
    "  the histograms). This is mainly because it makes the assumption that features\n",
    "  are conditionally independent given the class, which is not the case in this\n",
    "  dataset which contains 2 redundant features.\n",
    "\n",
    "* RandomForestClassifier shows the opposite behavior: the histograms show\n",
    "  peaks at approx. 0.2 and 0.9 probability, while probabilities close to 0 or 1\n",
    "  are very rare. An explanation for this is given by Niculescu-Mizil and Caruana\n",
    "  [1]_: \"Methods such as bagging and random forests that average predictions\n",
    "  from a base set of models can have difficulty making predictions near 0 and 1\n",
    "  because variance in the underlying base models will bias predictions that\n",
    "  should be near zero or one away from these values. Because predictions are\n",
    "  restricted to the interval [0,1], errors caused by variance tend to be one-\n",
    "  sided near zero and one. For example, if a model should predict p = 0 for a\n",
    "  case, the only way bagging can achieve this is if all bagged trees predict\n",
    "  zero. If we add noise to the trees that bagging is averaging over, this noise\n",
    "  will cause some trees to predict values larger than 0 for this case, thus\n",
    "  moving the average prediction of the bagged ensemble away from 0. We observe\n",
    "  this effect most strongly with random forests because the base-level trees\n",
    "  trained with random forests have relatively high variance due to feature\n",
    "  subsetting.\" As a result, the calibration curve shows a characteristic\n",
    "  sigmoid shape, indicating that the classifier could trust its \"intuition\"\n",
    "  more and return probabilities closer to 0 or 1 typically.\n",
    "\n",
    "* Support Vector Classification (SVC) shows an even more sigmoid curve as\n",
    "  the  RandomForestClassifier, which is typical for maximum-margin methods\n",
    "  (compare Niculescu-Mizil and Caruana [1]_), which focus on hard samples\n",
    "  that are close to the decision boundary (the support vectors).\n",
    "\n",
    ".. topic:: References:\n",
    "\n",
    "    .. [1] Predicting Good Probabilities with Supervised Learning,\n",
    "          A. Niculescu-Mizil & R. Caruana, ICML 2005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Jan Hendrik Metzen <jhm@informatik.uni-bremen.de>\n",
    "# License: BSD Style.\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=100000, n_features=20,\n",
    "                                    n_informative=2, n_redundant=2)\n",
    "\n",
    "train_samples = 100  # Samples used for training the models\n",
    "\n",
    "X_train = X[:train_samples]\n",
    "X_test = X[train_samples:]\n",
    "y_train = y[:train_samples]\n",
    "y_test = y[train_samples:]\n",
    "\n",
    "# Create classifiers\n",
    "lr = LogisticRegression()\n",
    "gnb = GaussianNB()\n",
    "svc = LinearSVC(C=1.0)\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Plot calibration plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "for clf, name in [(lr, 'Logistic'),\n",
    "                  (gnb, 'Naive Bayes'),\n",
    "                  (svc, 'Support Vector Classification'),\n",
    "                  (rfc, 'Random Forest')]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        prob_pos = clf.predict_proba(X_test)[:, 1]\n",
    "    else:  # use decision function\n",
    "        prob_pos = clf.decision_function(X_test)\n",
    "        prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "    fraction_of_positives, mean_predicted_value =  calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "\n",
    "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "             label=\"%s\" % (name, ))\n",
    "\n",
    "    ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
    "             histtype=\"step\", lw=2)\n",
    "\n",
    "ax1.set_ylabel(\"Fraction of positives\")\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.set_title('Calibration plots  (reliability curve)')\n",
    "\n",
    "ax2.set_xlabel(\"Mean predicted value\")\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.legend(loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
