{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./helpers_models/')\n",
    "sys.path.append('./data_visualization_and_augmentations/')\n",
    "sys.path.append('../torch_videovision/')\n",
    "sys.path.append('../3D-ResNets-PyTorch/')\n",
    "sys.path.append('./important_csvs/')\n",
    "\n",
    "from helpers_3d import *\n",
    "from helpers_training import *\n",
    "from focal_loss_2 import *\n",
    "from load_data_and_augmentations import *\n",
    "from imbalanced_sampler_3 import MultilabelBalancedRandomSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = get_tensor_transform('Kinetics', False)\n",
    "train_spat_transform = get_spatial_transform(1)\n",
    "train_temp_transform = va.TemporalFit(size=16)\n",
    "#train_temp_transform = get_temporal_transform(16)\n",
    "valid_spat_transform = get_spatial_transform(0)\n",
    "valid_temp_transform = va.TemporalFit(size=16)\n",
    "\n",
    "root_dir = '/media/scratch/astamoulakatos/centre_Ch2/'\n",
    "df = pd.read_csv('./important_csvs/more_balanced_dataset/big_stratified_new.csv')\n",
    "\n",
    "####################################################\n",
    "bs = 20\n",
    "df_train = get_df(df, 50, True, False, False)\n",
    "class_image_paths, end_idx, idx_label = get_indices(df_train, root_dir)\n",
    "seq_length = 50\n",
    "indices, labels = get_final_indices_train(idx_label, end_idx, 'overlap', skip_frames=15, set_step=25, seq_length=seq_length, per_label=True)\n",
    "indices = torch.cat(indices)\n",
    "indices = indices[torch.randperm(len(indices))]\n",
    "labels = []\n",
    "for i in class_image_paths:\n",
    "    labels.append(i[2])\n",
    "labels = np.array(labels)\n",
    "train_sampler = MultilabelBalancedRandomSampler(\n",
    "    labels, indices, class_choice=\"least_sampled\"\n",
    ")\n",
    "dataset = MyDataset(\n",
    "        image_paths = class_image_paths,\n",
    "        seq_length = seq_length,\n",
    "        temp_transform = train_temp_transform,\n",
    "        spat_transform = train_spat_transform,\n",
    "        tensor_transform = tensor_transform,\n",
    "        length = len(train_sampler),\n",
    "        lstm = False,\n",
    "        oned = False,\n",
    "        augment = True,\n",
    "        multi = 1)\n",
    "train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = bs,\n",
    "        sampler = train_sampler,\n",
    "        drop_last = True,\n",
    "        num_workers = 0)\n",
    "##########################################################################################\n",
    "\n",
    "#train_loader = get_loader(16, 64, end_idx, class_image_paths, train_temp_transform, train_spat_transform, tensor_transform, False, False)\n",
    "df_valid = get_df(df, 50, False, True, False)\n",
    "class_image_paths, end_idx, idx_label= get_indices(df_valid, root_dir)\n",
    "indices, labels = get_final_indices_valid(idx_label, end_idx, 'overlap', skip_frames=15, set_step=25, seq_length=seq_length, per_label=True)\n",
    "valid_loader, valid_dataset = get_loader_new(seq_length, bs, indices, class_image_paths, valid_temp_transform,\n",
    "                                             valid_spat_transform, tensor_transform, False, False, True, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 16, 576, 704])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.955555555555556"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "223/45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
