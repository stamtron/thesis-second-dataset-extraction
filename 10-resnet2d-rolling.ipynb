{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./helpers_models/')\n",
    "sys.path.append('./data_visualization_and_augmentations/')\n",
    "sys.path.append('../torch_videovision/')\n",
    "sys.path.append('./important_csvs/')\n",
    "\n",
    "from helpers_resnet import *\n",
    "\n",
    "resnet = torchvision.models.resnet50(pretrained=True)\n",
    "adaptive_pooling = AdaptiveConcatPool2d()\n",
    "head = Head()\n",
    "resnet.avgpool = adaptive_pooling\n",
    "resnet.fc = head\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2'\n",
    "\n",
    "resnet = resnet.cuda()\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in resnet.avgpool.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet = nn.DataParallel(resnet)\n",
    "check_freeze(resnet.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = get_tensor_transform('ImageNet', True)\n",
    "train_spat_transform = get_spatial_transform(2)\n",
    "train_temp_transform = get_temporal_transform()\n",
    "valid_spat_transform = get_spatial_transform(0)\n",
    "valid_temp_transform = va.TemporalFit(size=16)\n",
    "\n",
    "root_dir = '/media/scratch/astamoulakatos/nsea_video_jpegs/'\n",
    "df = pd.read_csv('./small_dataset_csvs/events_with_number_of_frames_stratified.csv')\n",
    "df_train = get_df(df, 20, False, True, False)\n",
    "class_image_paths, end_idx = get_indices(df_train, root_dir)\n",
    "train_loader = get_loader(16, 1, end_idx, class_image_paths, train_temp_transform, train_spat_transform, tensor_transform, False, False)\n",
    "df_valid = get_df(df, 20, False, True, False)\n",
    "class_image_paths, end_idx = get_indices(df_valid, root_dir)\n",
    "valid_loader = get_loader(16, 1, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, False, False)\n",
    "df_test = get_df(df, 20, False, False, True)\n",
    "class_image_paths, end_idx = get_indices(df_test, root_dir)\n",
    "test_loader = get_loader(16, 1, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, False, False)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,f1_score, accuracy_score, jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0  \n",
    "running_f1 = 0.0\n",
    "valid_result = []\n",
    "rolling_preds = np.zeros(5)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for X, y in valid_loader:\n",
    "        X = X.cuda()\n",
    "        y = Variable(y.float()).cuda()\n",
    "        X = X.squeeze(dim=0)\n",
    "        X = X.permute(1,0,2,3)\n",
    "        y = y.squeeze(dim=0)\n",
    "        y = y.float()\n",
    "        output = resnet(X)\n",
    "        preds = torch.sigmoid(output) #.data > 0.5  \n",
    "        preds = preds.to(torch.float32)  \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        cl1 = []\n",
    "        cl2 = []\n",
    "        cl3 = []\n",
    "        cl4 = []\n",
    "        cl5 = []\n",
    "        for p in preds:\n",
    "            cl1.append(p[0])\n",
    "            cl2.append(p[1])\n",
    "            cl3.append(p[2])\n",
    "            cl4.append(p[3])\n",
    "            cl5.append(p[4])\n",
    "\n",
    "        if (np.mean(cl1) > 0.5):\n",
    "            rolling_preds[0] = 1\n",
    "        else:\n",
    "            rolling_preds[0] = 0\n",
    "\n",
    "        if (np.mean(cl2) > 0.7):\n",
    "            rolling_preds[1] = 1\n",
    "        else:\n",
    "            rolling_preds[1] = 0   \n",
    "\n",
    "        if (np.mean(cl3) > 0.3):\n",
    "            rolling_preds[2] = 1\n",
    "        else:\n",
    "            rolling_preds[2] = 0\n",
    "\n",
    "        if (np.mean(cl4) > 0.8):\n",
    "            rolling_preds[3] = 1\n",
    "        else:\n",
    "            rolling_preds[3] = 0 \n",
    "\n",
    "        if (np.mean(cl5) > 0.8):\n",
    "            rolling_preds[4] = 1\n",
    "        else:\n",
    "            rolling_preds[4] = 0        \n",
    "\n",
    "        #running_acc += accuracy_score(y.detach().cpu().numpy(), rolling_preds) *  X.size(0)\n",
    "        #running_f1 += f1_score(y.detach().cpu().numpy(), (rolling_preds), average=\"samples\")  *  X.size(0)\n",
    "        y_pred.append(rolling_preds)\n",
    "        y_true.append(y.detach().cpu().numpy())\n",
    "\n",
    "# epoch_acc = running_acc / len(valid_loader.dataset)\n",
    "# epoch_f1 = running_f1 / len(valid_loader.dataset)\n",
    "\n",
    "# valid_result.append('Validation Acc: {:.4f} F1: {:.4f}'.format(epoch_acc, epoch_f1))\n",
    "# print(valid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_thresholds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Exposure', 'Burial', 'Field Joint', 'Anode', 'Free Span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = nsea_compute_thresholds(y_true, y_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compute_metrics(y_tr, y_pr, thresholds, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0  \n",
    "running_f1 = 0.0\n",
    "valid_result = []\n",
    "rolling_preds = np.zeros(5)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.cuda()\n",
    "        y = Variable(y.float()).cuda()\n",
    "        X = X.squeeze(dim=0)\n",
    "        X = X.permute(1,0,2,3)\n",
    "        y = y.squeeze(dim=0)\n",
    "        y = y.float()\n",
    "        output = resnet(X)\n",
    "        preds = torch.sigmoid(output) #.data > 0.5  \n",
    "        preds = preds.to(torch.float32)  \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        cl1 = []\n",
    "        cl2 = []\n",
    "        cl3 = []\n",
    "        cl4 = []\n",
    "        cl5 = []\n",
    "        for p in preds:\n",
    "            cl1.append(p[0])\n",
    "            cl2.append(p[1])\n",
    "            cl3.append(p[2])\n",
    "            cl4.append(p[3])\n",
    "            cl5.append(p[4])\n",
    "\n",
    "        if (np.mean(cl1) > 0.5):\n",
    "            rolling_preds[0] = 1\n",
    "        else:\n",
    "            rolling_preds[0] = 0\n",
    "\n",
    "        if (np.mean(cl2) > 0.5):\n",
    "            rolling_preds[1] = 1\n",
    "        else:\n",
    "            rolling_preds[1] = 0   \n",
    "\n",
    "        if (np.mean(cl3) > 0.5):\n",
    "            rolling_preds[2] = 1\n",
    "        else:\n",
    "            rolling_preds[2] = 0\n",
    "\n",
    "        if (np.mean(cl4) > 0.5):\n",
    "            rolling_preds[3] = 1\n",
    "        else:\n",
    "            rolling_preds[3] = 0 \n",
    "\n",
    "        if (np.mean(cl5) > 0.5):\n",
    "            rolling_preds[4] = 1\n",
    "        else:\n",
    "            rolling_preds[4] = 0        \n",
    "\n",
    "        #running_acc += accuracy_score(y.detach().cpu().numpy(), rolling_preds) *  X.size(0)\n",
    "        #running_f1 += f1_score(y.detach().cpu().numpy(), (rolling_preds), average=\"samples\")  *  X.size(0)\n",
    "        y_pred.append(rolling_preds)\n",
    "        y_true.append(y.detach().cpu().numpy())\n",
    "\n",
    "# epoch_acc = running_acc / len(valid_loader.dataset)\n",
    "# epoch_f1 = running_f1 / len(valid_loader.dataset)\n",
    "\n",
    "# valid_result.append('Validation Acc: {:.4f} F1: {:.4f}'.format(epoch_acc, epoch_f1))\n",
    "# print(valid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compute_metrics(y_tr, y_pr, thresholds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
