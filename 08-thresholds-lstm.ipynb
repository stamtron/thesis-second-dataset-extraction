{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./helpers_models/')\n",
    "sys.path.append('./data_visualization_and_augmentations/')\n",
    "sys.path.append('../torch_videovision/')\n",
    "sys.path.append('./important_csvs/')\n",
    "sys.path.append('../video-classification/ResNetCRNN/')\n",
    "\n",
    "from helpers_lstm import *\n",
    "from helpers_training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = get_tensor_transform('ImageNet', True)\n",
    "train_spat_transform = get_spatial_transform(2)\n",
    "train_temp_transform = get_temporal_transform()\n",
    "valid_spat_transform = get_spatial_transform(0)\n",
    "valid_temp_transform = va.TemporalFit(size=16)\n",
    "\n",
    "root_dir = '/media/scratch/astamoulakatos/nsea_video_jpegs/'\n",
    "df = pd.read_csv('./small_dataset_csvs/events_with_number_of_frames_stratified.csv')\n",
    "df_train = get_df(df, 20, True, False, False)\n",
    "class_image_paths, end_idx = get_indices(df_train, root_dir)\n",
    "train_loader = get_loader(16, 128, end_idx, class_image_paths, train_temp_transform, train_spat_transform, tensor_transform, True, False)\n",
    "df_valid = get_df(df, 20, False, True, False)\n",
    "class_image_paths, end_idx = get_indices(df_valid, root_dir)\n",
    "valid_loader = get_loader(16, 128, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, True, False)\n",
    "df_test = get_df(df, 20, False, False, True)\n",
    "class_image_paths, end_idx = get_indices(df_test, root_dir)\n",
    "test_loader = get_loader(16, 128, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "cnn_encoder = ResCNNEncoder().to(device)\n",
    "adaptive_pool = AdaptiveConcatPool2d()\n",
    "cnn_encoder.resnet[8] = adaptive_pool\n",
    "for param in cnn_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in cnn_encoder.resnet[8].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in cnn_encoder.headbn1.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in cnn_encoder.fc1.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "rnn_decoder = DecoderRNNattention(batch_size=128).to(device)\n",
    "for param in rnn_decoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn_params, cnn_encoder, rnn_decoder = parallelize_model(cnn_encoder, rnn_decoder)\n",
    "\n",
    "model = nn.Sequential(cnn_encoder,rnn_decoder)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/media/scratch/astamoulakatos/saved-lstm-models/first-round-same-dataset/best-checkpoint-000epoch.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print('loading pretrained freezed model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for X, y in valid_loader:\n",
    "        X = X.to(device)\n",
    "        y = Variable(y.float()).to(device) \n",
    "        y = y.squeeze(dim=1)\n",
    "        y = y.float()\n",
    "        output = model(X)\n",
    "        y = y.detach().cpu()\n",
    "        #loss = criterion(output, y)\n",
    "        preds = torch.sigmoid(output)\n",
    "        preds = preds.to(torch.float32) \n",
    "        preds = preds.detach().cpu()\n",
    "        y_pred.append(preds)\n",
    "        y_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.vstack([t.__array__() for tensor in y_true for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = np.vstack([t.__array__() for tensor in y_pred for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_thresholds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Exposure', 'Burial', 'Field Joint', 'Anode', 'Free Span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = nsea_compute_thresholds(y_tr, y_pr, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compute_metrics(y_tr, y_pr, thresholds, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = Variable(y.float()).to(device) \n",
    "        y = y.squeeze(dim=1)\n",
    "        y = y.float()\n",
    "        output = model(X)\n",
    "        y = y.detach().cpu()\n",
    "        #loss = criterion(output, y)\n",
    "        preds = torch.sigmoid(output)\n",
    "        preds = preds.to(torch.float32) \n",
    "        preds = preds.detach().cpu()\n",
    "        y_pred.append(preds)\n",
    "        y_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.vstack([t.__array__() for tensor in y_true for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = np.vstack([t.__array__() for tensor in y_pred for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compute_metrics(y_tr, y_pr, thresholds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
