{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./helpers_models/')\n",
    "sys.path.append('./data_visualization_and_augmentations/')\n",
    "sys.path.append('../torch_videovision/')\n",
    "sys.path.append('./important_csvs/')\n",
    "\n",
    "from helpers_resnet import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 False\n",
      "bn1 False\n",
      "relu True\n",
      "maxpool True\n",
      "layer1 False\n",
      "layer2 False\n",
      "layer3 False\n",
      "layer4 False\n",
      "avgpool True\n",
      "fc True\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet50(pretrained=True)\n",
    "adaptive_pooling = AdaptiveConcatPool2d()\n",
    "head = Head()\n",
    "resnet.avgpool = adaptive_pooling\n",
    "resnet.fc = head\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2'\n",
    "\n",
    "resnet = resnet.cuda()\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in resnet.avgpool.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet = nn.DataParallel(resnet)\n",
    "check_freeze(resnet.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_thresholds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "font = {'family' : 'DejaVu Sans',  'weight' : 'normal',  'size'  : 40}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = get_tensor_transform('ImageNet', False)\n",
    "train_spat_transform = get_spatial_transform(2)\n",
    "train_temp_transform = get_temporal_transform()\n",
    "valid_spat_transform = get_spatial_transform(0)\n",
    "valid_temp_transform = va.TemporalFit(size=16)\n",
    "\n",
    "bs = 50\n",
    "root_dir = '/media/scratch/astamoulakatos/nsea_video_jpegs/'\n",
    "df = pd.read_csv('./small_dataset_csvs/events_with_number_of_frames_stratified.csv')\n",
    "# df_train = get_df(df, 20, True, False, False)\n",
    "# class_image_paths, end_idx, idx_label= get_indices(df_train, root_dir)\n",
    "# train_loader = get_loader(1, 128, end_idx, class_image_paths, train_temp_transform, train_spat_transform, tensor_transform, False, True, True, 1)\n",
    "df_valid = get_df(df, 20, False, True, False)\n",
    "class_image_paths, end_idx, idx_label = get_indices(df_valid, root_dir)\n",
    "valid_loader, valid_dataset = get_loader(1, bs, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, False, True, True, 1)\n",
    "df_test = get_df(df, 20, False, False, True)\n",
    "class_image_paths, end_idx, idx_label = get_indices(df_test, root_dir)\n",
    "test_loader, test_dataset = get_loader(1, bs, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, False, True, True, 1)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained freezed model!\n"
     ]
    }
   ],
   "source": [
    "load = True\n",
    "if load:\n",
    "    checkpoint = torch.load('/media/scratch/astamoulakatos/saved-resnet-models/fifth-small-aug-final/best-checkpoint-010epoch.pth')\n",
    "    resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print('loading pretrained freezed model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1.],\n",
       "        [1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from more_losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warp_lsep import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_warp_1 = loss_warp(outputs.cuda(), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<WARPBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_warp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lsep_1 = loss_lsep(torch.sigmoid(outputs.cuda()), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<LSEPBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_lsep_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, _ = resnet(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lsep_loss_stable(outputs.cuda(), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5562, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.9500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.9500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_smo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = lsep_loss(outputs.cuda(), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bce_1 = binary_cross_entropy(outputs.cuda(), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4576, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_bce_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_focal_1 = focal_loss(outputs.cuda(), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0836, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_focal_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focal_loss_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_wei = torch.tensor([1, 1, 3, 3, 1])\n",
    "pos_wei = pos_wei.cuda()\n",
    "#criterion = nn.BCEWithLogitsLoss(pos_weight = pos_wei)\n",
    "criterion = FocalLoss2d(weight=pos_wei,reduction='mean',balance_param=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_focal_2 = criterion(outputs.cuda(), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1650, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_focal_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_wei = torch.tensor([1, 1, 3, 3, 1])\n",
    "pos_wei = pos_wei.cuda()\n",
    "criterion2 = nn.BCEWithLogitsLoss(pos_weight = pos_wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bce_2 = criterion2(outputs.cuda(), labels_smo.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6791, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_bce_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = outputs.unsqueeze(1) - outputs.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0.0000,   5.7382,  -1.4639,  -0.5500,  -0.6794],\n",
       "         [ -5.7382,   0.0000,  -7.2021,  -6.2882,  -6.4176],\n",
       "         [  1.4639,   7.2021,   0.0000,   0.9139,   0.7845],\n",
       "         [  0.5500,   6.2882,  -0.9139,   0.0000,  -0.1294],\n",
       "         [  0.6794,   6.4176,  -0.7845,   0.1294,   0.0000]],\n",
       "\n",
       "        [[  0.0000,   9.0546,   1.2798,   0.6682,  -1.0879],\n",
       "         [ -9.0546,   0.0000,  -7.7748,  -8.3865, -10.1425],\n",
       "         [ -1.2798,   7.7748,   0.0000,  -0.6117,  -2.3677],\n",
       "         [ -0.6682,   8.3865,   0.6117,   0.0000,  -1.7560],\n",
       "         [  1.0879,  10.1425,   2.3677,   1.7560,   0.0000]],\n",
       "\n",
       "        [[  0.0000,   9.6342,   0.4911,  -0.8545,  -0.1156],\n",
       "         [ -9.6342,   0.0000,  -9.1432, -10.4887,  -9.7499],\n",
       "         [ -0.4911,   9.1432,   0.0000,  -1.3456,  -0.6067],\n",
       "         [  0.8545,  10.4887,   1.3456,   0.0000,   0.7389],\n",
       "         [  0.1156,   9.7499,   0.6067,  -0.7389,   0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.0000,   2.7682,  -1.7709,  -1.0570,  -3.6197],\n",
       "         [ -2.7682,   0.0000,  -4.5391,  -3.8252,  -6.3880],\n",
       "         [  1.7709,   4.5391,   0.0000,   0.7139,  -1.8488],\n",
       "         [  1.0570,   3.8252,  -0.7139,   0.0000,  -2.5628],\n",
       "         [  3.6197,   6.3880,   1.8488,   2.5628,   0.0000]],\n",
       "\n",
       "        [[  0.0000, -11.8443, -12.3634, -12.6024,  18.1219],\n",
       "         [ 11.8443,   0.0000,  -0.5191,  -0.7581,  29.9662],\n",
       "         [ 12.3634,   0.5191,   0.0000,  -0.2390,  30.4853],\n",
       "         [ 12.6024,   0.7581,   0.2390,   0.0000,  30.7242],\n",
       "         [-18.1219, -29.9662, -30.4853, -30.7242,   0.0000]],\n",
       "\n",
       "        [[  0.0000,  -9.9053,  -5.0259,  -6.0228,  -9.4267],\n",
       "         [  9.9053,   0.0000,   4.8794,   3.8825,   0.4786],\n",
       "         [  5.0259,  -4.8794,   0.0000,  -0.9969,  -4.4008],\n",
       "         [  6.0228,  -3.8825,   0.9969,   0.0000,  -3.4039],\n",
       "         [  9.4267,  -0.4786,   4.4008,   3.4039,   0.0000]]], device='cuda:0',\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_different = (labels.unsqueeze(1) < labels.unsqueeze(2)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 5])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 5, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_un = labels.unsqueeze(2); labels_un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 5, 5])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_different.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = differences.cuda().exp() * where_different.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [3.2206e-03, 0.0000e+00, 7.4500e-04, 1.8580e-03, 1.6325e-03],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.1685e-04, 0.0000e+00, 4.2018e-04, 2.2793e-04, 3.9370e-05],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [6.5449e-05, 0.0000e+00, 1.0695e-04, 2.7849e-05, 5.8303e-05],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [6.2772e-02, 0.0000e+00, 1.0683e-02, 2.1814e-02, 1.6817e-03],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 7.1795e-06, 4.2721e-06, 3.3641e-06, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 9.6796e-14, 5.7598e-14, 4.5356e-14, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 4.9909e-05, 0.0000e+00, 2.4229e-03, 8.0547e-05],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 7.6016e-03, 0.0000e+00, 3.6903e-01, 1.2268e-02],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsep = torch.log(1 + exps.sum(2).sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsep.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_smoothing = 0.1\n",
    "labels_smo = labels * (1 - label_smoothing) + 0.5 * label_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.9500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.9500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.0500, 0.9500, 0.0500, 0.0500, 0.0500],\n",
       "        [0.9500, 0.0500, 0.0500, 0.0500, 0.9500],\n",
       "        [0.9500, 0.0500, 0.9500, 0.0500, 0.0500]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_smo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.net import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet(\n",
    "    resnet.module,\n",
    "    max_epochs=20,\n",
    "    verbose=0,\n",
    "    criterion=nn.BCEWithLogitsLoss(),\n",
    "    device='cuda',\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fit(valid_dataset, y=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BinaryRelevance(classifier=net, require_dense=[True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [y for x, y in iter(valid_loader.dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(torch.stack(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = valid_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [y for x, y in iter(valid_loader.dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [x for x, y in iter(valid_loader.dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(torch.cat(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels), len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
