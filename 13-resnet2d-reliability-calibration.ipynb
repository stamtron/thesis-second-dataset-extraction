{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('./helpers_models/')\n",
    "sys.path.append('./data_visualization_and_augmentations/')\n",
    "sys.path.append('../torch_videovision/')\n",
    "sys.path.append('./important_csvs/')\n",
    "\n",
    "from helpers_resnet import *\n",
    "\n",
    "resnet = torchvision.models.resnet50(pretrained=True)\n",
    "adaptive_pooling = AdaptiveConcatPool2d()\n",
    "head = Head()\n",
    "resnet.avgpool = adaptive_pooling\n",
    "resnet.fc = head\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0' #,1,2\n",
    "\n",
    "resnet = resnet.cuda()\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in resnet.avgpool.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "resnet = nn.DataParallel(resnet)\n",
    "check_freeze(resnet.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_thresholds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,6)\n",
    "font = {'family' : 'DejaVu Sans',  'weight' : 'normal',  'size'  : 40}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transform = get_tensor_transform('ImageNet', False)\n",
    "train_spat_transform = get_spatial_transform(2)\n",
    "train_temp_transform = get_temporal_transform()\n",
    "valid_spat_transform = get_spatial_transform(0)\n",
    "valid_temp_transform = va.TemporalFit(size=16)\n",
    "\n",
    "root_dir = '/media/scratch/astamoulakatos/nsea_video_jpegs/'\n",
    "df = pd.read_csv('./small_dataset_csvs/events_with_number_of_frames_stratified.csv')\n",
    "# df_train = get_df(df, 20, True, False, False)\n",
    "# class_image_paths, end_idx, idx_label= get_indices(df_train, root_dir)\n",
    "# train_loader = get_loader(1, 128, end_idx, class_image_paths, train_temp_transform, train_spat_transform, tensor_transform, False, True, True, 1)\n",
    "df_valid = get_df(df, 20, False, True, False)\n",
    "class_image_paths, end_idx, idx_label = get_indices(df_valid, root_dir)\n",
    "valid_loader = get_loader(1, 50, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, False, True, True, 1)\n",
    "df_test = get_df(df, 20, False, False, True)\n",
    "class_image_paths, end_idx, idx_label = get_indices(df_test, root_dir)\n",
    "test_loader = get_loader(1, 50, end_idx, class_image_paths, valid_temp_transform, valid_spat_transform, tensor_transform, False, True, True, 1)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "if load:\n",
    "    checkpoint = torch.load('/media/scratch/astamoulakatos/saved-resnet-models/fifth-small-aug-final/best-checkpoint-010epoch.pth')\n",
    "    resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print('loading pretrained freezed model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temperature_scaling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_model = ModelWithTemperature(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_model.set_temperature(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_model.model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = Variable(y.float()).to(device) \n",
    "        #X = X.permute(0,2,1,3,4)\n",
    "        y = y.squeeze(dim=1)\n",
    "        y = y.float()\n",
    "        output, _ = scaled_model.model(X)\n",
    "        y = y.detach().cpu()\n",
    "        #loss = criterion(output, y)\n",
    "        preds = torch.sigmoid(output)\n",
    "        preds = preds.to(torch.float32) \n",
    "        preds = preds.detach().cpu()\n",
    "        y_pred.append(preds)\n",
    "        y_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = torch.cat(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = torch.cat(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = y_pr.numpy()\n",
    "y_tr = y_tr.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_thresholds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_tr = np.vstack([t.__array__() for tensor in y_true for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pr = np.vstack([t.__array__() for tensor in y_pred for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Exposure', 'Burial', 'Field Joint', 'Anode', 'Free Span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curves(0.0, y_tr, y_pr, classes, '_2d_full_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = nsea_compute_thresholds(y_tr, y_pr, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresholds = pd.DataFrame({'Threshold': thresholds}).T\n",
    "df_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_thresholds.to_latex(float_format=lambda x: '%.3f' % truncate_decimals(x,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_valid = new_compute_metrics(y_tr, y_pr, thresholds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for X, y in valid_loader:\n",
    "        X = X.to(device)\n",
    "        y = Variable(y.float()).to(device) \n",
    "        #X = X.permute(0,2,1,3,4)\n",
    "        y = y.squeeze(dim=1)\n",
    "        y_cl = y\n",
    "        y = y.float()\n",
    "        output, _ = resnet(X)\n",
    "        y = y.detach().cpu().numpy()\n",
    "        #loss = criterion(output, y)\n",
    "        preds = torch.sigmoid(output)\n",
    "        predicted_cl = preds.data > 0.5\n",
    "        predicted_cl = predicted_cl.to(torch.float32) \n",
    "        preds = preds.to(torch.float32) \n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(y)\n",
    "        correct += sum(sum(predicted_cl == y_cl)).item()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(predicted_cl == y_cl)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cl.shape, predicted_cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(y_pred).flatten()\n",
    "labels_oneh = np.array(y_true).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_oneh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_loader.dataset)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_perc = correct / (len(valid_loader.dataset)*5)\n",
    "print('Accuracy of the network on the validation set images: %d %%' % (100 * correct_perc))\n",
    "print(correct_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bins(preds):\n",
    "  # Assign each prediction to a bin\n",
    "    num_bins = 10\n",
    "    bins = np.linspace(0.1, 1, num_bins)\n",
    "    binned = np.digitize(preds, bins)\n",
    "\n",
    "  # Save the accuracy, confidence and size of each bin\n",
    "    bin_accs = np.zeros(num_bins)\n",
    "    bin_confs = np.zeros(num_bins)\n",
    "    bin_sizes = np.zeros(num_bins)\n",
    "\n",
    "    for bin in range(num_bins):\n",
    "        bin_sizes[bin] = len(preds[binned == bin])\n",
    "        if bin_sizes[bin] > 0:\n",
    "            bin_accs[bin] = (labels_oneh[binned==bin]).sum() / bin_sizes[bin]\n",
    "            bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
    "   \n",
    "    return bins, binned, bin_accs, bin_confs, bin_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(preds):\n",
    "    ECE = 0\n",
    "    MCE = 0\n",
    "    bins, _, bin_accs, bin_confs, bin_sizes = calc_bins(preds)\n",
    "\n",
    "    for i in range(len(bins)):\n",
    "        abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
    "        ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
    "        MCE = max(MCE, abs_conf_dif)\n",
    "\n",
    "    return ECE, MCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def draw_reliability_graph(preds):\n",
    "    ECE, MCE = get_metrics(preds)\n",
    "    bins, _, bin_accs, _, _ = calc_bins(preds)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.gca()\n",
    "\n",
    "  # x/y limits\n",
    "    ax.set_xlim(0, 1.05)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "  # x/y labels\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "  # Create grid\n",
    "    ax.set_axisbelow(True) \n",
    "    ax.grid(color='gray', linestyle='dashed')\n",
    "\n",
    "  # Error bars\n",
    "    plt.bar(bins, bins,  width=0.1, alpha=0.3, edgecolor='black', color='r', hatch='\\\\')\n",
    "\n",
    "  # Draw bars and identity line\n",
    "    plt.bar(bins, bin_accs, width=0.1, alpha=1, edgecolor='black', color='b')\n",
    "    plt.plot([0,1],[0,1], '--', color='gray', linewidth=2)\n",
    "\n",
    "  # Equally spaced axes\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "  # ECE and MCE legend\n",
    "    ECE_patch = mpatches.Patch(color='green', label='ECE = {:.2f}%'.format(ECE*100))\n",
    "    MCE_patch = mpatches.Patch(color='red', label='MCE = {:.2f}%'.format(MCE*100))\n",
    "    plt.legend(handles=[ECE_patch, MCE_patch])\n",
    "\n",
    "  #plt.show()\n",
    "  \n",
    "    plt.savefig('calibrated_network.png', bbox_inches='tight')\n",
    "\n",
    "#draw_reliability_graph(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_reliability_graph(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_scaling(logits, args):\n",
    "    temperature = args.get('temperature', None)\n",
    "    assert temperature, 'You need to provide the temperature variable in kwargs'\n",
    "    temperature = temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
    "    return logits / temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focal_loss_2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = nn.Parameter(torch.ones(1).cuda())\n",
    "pos_wei = torch.tensor([1, 1, 1.5, 1.5, 1])\n",
    "pos_wei = pos_wei.cuda()\n",
    "#criterion = nn.BCEWithLogitsLoss(pos_weight = pos_wei)\n",
    "criterion = FocalLoss2d(weight=pos_wei,reduction='mean',balance_param=1)\n",
    "optimizer = optim.LBFGS([temperature], lr=0.001, max_iter=10000, line_search_fn='strong_wolfe')\n",
    "\n",
    "logits_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'temperature': temperature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(tqdm(valid_loader, 0)):\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        out, _ = resnet(images)\n",
    "        logits_list.append(out)\n",
    "        labels_list.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = torch.cat(labels_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors\n",
    "logits_list = torch.cat(logits_list).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval():\n",
    "    loss = criterion(T_scaling(logits_list, args), labels_list)\n",
    "    loss.backward()\n",
    "    temps.append(temperature.item())\n",
    "    losses.append(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step(_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final T_scaling factor: {:.2f}'.format(temperature.item()))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(list(range(len(temps))), temps)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(list(range(len(losses))), losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, calibration_method=None, **kwargs):\n",
    "    resnet.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    correct = 0\n",
    "    y_predss = []\n",
    "    y_truess = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X = X.to(device)\n",
    "            y = Variable(y.float()).to(device) \n",
    "            #X = X.permute(0,2,1,3,4)\n",
    "            y = y.squeeze(dim=1)\n",
    "            y_cl = y\n",
    "            y = y.float()\n",
    "            output, _ = resnet(X)\n",
    "            y = y.detach().cpu().numpy()\n",
    "            #loss = criterion(output, y)\n",
    "            if calibration_method:\n",
    "                output = calibration_method(output, kwargs)\n",
    "                \n",
    "            preds = torch.sigmoid(output)\n",
    "            predicted_cl = preds.data > 0.5\n",
    "            predicted_cl = predicted_cl.to(torch.float32) \n",
    "            preds = preds.to(torch.float32) \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(y)\n",
    "            correct += sum(sum(predicted_cl == y_cl)).item()\n",
    "            y_predss.append(preds)\n",
    "            y_truess.append(y)\n",
    "            \n",
    "    preds = np.array(y_pred).flatten()\n",
    "    labels_oneh = np.array(y_true).flatten()\n",
    "            \n",
    "    correct_perc = correct / (len(valid_loader.dataset)*5)\n",
    "    print('Accuracy of the network on the validation set images: %d %%' % (100 * correct_perc))\n",
    "    print(correct_perc)\n",
    "    return preds, labels_oneh, y_predss, y_truess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_calibrated, _, y_pred, y_true = test(T_scaling, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_reliability_graph(preds_calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_thresholds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.vstack([t.__array__() for tensor in y_true for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = np.vstack([t.__array__() for tensor in y_pred for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Exposure', 'Burial', 'Field Joint', 'Anode', 'Free Span']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curves(0.0, y_tr, y_pr, classes, '_2d_full_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = nsea_compute_thresholds(y_tr, y_pr, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thresholds = pd.DataFrame({'Threshold': thresholds}).T\n",
    "df_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_thresholds.to_latex(float_format=lambda x: '%.3f' % truncate_decimals(x,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_valid = new_compute_metrics(y_tr, y_pr, thresholds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_calibrated, _, y_pred, y_true = test(test_loader, T_scaling, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_reliability_graph(preds_calibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.vstack([t.__array__() for tensor in y_true for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = np.vstack([t.__array__() for tensor in y_pred for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test = new_compute_metrics(y_tr, y_pr, thresholds, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_test.to_latex(float_format=lambda x: '%.3f' % truncate_decimals(x,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(y_tr, y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(testy, yhat_uncalibrated, n_bins=10, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
