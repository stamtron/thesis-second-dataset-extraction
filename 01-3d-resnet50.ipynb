{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "#from helpers import *\n",
    "from pathlib import Path\n",
    "#from fastai.callbacks.hooks import *\n",
    "from PIL import ImageFilter\n",
    "import numpy\n",
    "from torchvision import transforms\n",
    "import re\n",
    "#import torchsummary\n",
    "from PIL import Image\n",
    "import sys\n",
    "from collections import namedtuple\n",
    "from torchsummary1 import summary\n",
    "import glob\n",
    "from dataloader import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../3D-ResNets-PyTorch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting hyperparameters and loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"model_depth\": 50,\n",
    "    \"model\": 'resnet',\n",
    "    \"n_classes\": 400,\n",
    "    \"n_finetune_classes\": 5,\n",
    "    \"resnet_shortcut\": 'B',\n",
    "    \"sample_size\": (576,704),\n",
    "    \"sample_duration\": 16,\n",
    "    \"pretrain_path\": '../3D-ResNets-PyTorch/resnet-50-kinetics.pth',\n",
    "    \"no_cuda\": False,\n",
    "    \"arch\": 'resnet-50',\n",
    "    \"ft_begin_index\": 0\n",
    "}\n",
    "\n",
    "opts = namedtuple(\"opts\", sorted(options.keys()))\n",
    "\n",
    "myopts2 = opts(**options)\n",
    "#myopts2.model_depth\n",
    "\n",
    "#generate_model(myopts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import generate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(math.ceil(576 / 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, parameters = generate_model(myopts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3,8,576,704))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parallelize model to multiple GPUs\n",
    "\n",
    "# print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "# model1 = nn.DataParallel(model, device_ids = [1,0])\n",
    "# model1.to(f'cuda:{model.device_ids[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/scratch/astamoulakatos/nsea_video_jpegs/'\n",
    "class_paths = [d.path for d in os.scandir(root_dir) if d.is_dir]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((576, 704)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class_names = ['exp_and','exp_fs','exp','exp_fj','bur']\n",
    "one_hot_classes = [[1,0,1,0,0],[1,0,0,0,1],[1,0,0,0,0],[1,0,0,1,0],[0,1,0,0,0]]\n",
    "\n",
    "df = pd.read_csv('./train-valid-splits-video/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_image_paths = []\n",
    "end_idx = []\n",
    "for c, class_path in enumerate(class_paths):\n",
    "    for d in os.scandir(class_path):\n",
    "        if d.is_dir:\n",
    "            if d.path in df.videos.values:\n",
    "                paths = sorted(glob.glob(os.path.join(d.path, '*.png')))\n",
    "                # Add class idx to paths\n",
    "                paths = [(p, one_hot_classes[c]) for p in paths]\n",
    "                class_image_paths.extend(paths)\n",
    "                end_idx.extend([len(paths)])\n",
    "                \n",
    "end_idx = [0, *end_idx]\n",
    "end_idx = torch.cumsum(torch.tensor(end_idx), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MySampler(end_idx, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(\n",
    "    image_paths=class_image_paths,\n",
    "    seq_length=seq_length,\n",
    "    transform=transform,\n",
    "    length=len(sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=bs,\n",
    "    sampler=sampler,\n",
    "    num_workers=0,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "# inputs, classes = next(iter(loader))\n",
    "# inputs = inputs.squeeze(dim = 0)\n",
    "\n",
    "# for j in range(bs):\n",
    "#     # Make a grid from batch\n",
    "#     out = torchvision.utils.make_grid(inputs[j])\n",
    "\n",
    "\n",
    "#     for i, f in enumerate(one_hot_classes):\n",
    "#         if np.array_equal(classes[j][0].numpy(), np.asarray(f)):\n",
    "#             title = class_names[i]\n",
    "\n",
    "\n",
    "#     imshow(out, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from utils import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Detect devices\n",
    "# use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda:0\")   # use CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_epoch(epoch, data_loader, model, criterion, optimizer, opt, epoch_logger, batch_logger):\n",
    "epochs = 3\n",
    "save_model_path = './save-model-3d/'\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('train at epoch {}'.format(epoch))\n",
    "    model.train()\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "#     accuracies = AverageMeter()\n",
    "    end_time = time.time()\n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        data_time.update(time.time() - end_time)\n",
    "                                                    #cuda(non_blocking=True)\n",
    "        inputs = inputs.to(device).to(device)      #cuda(non_blocking=True)\n",
    "\n",
    "        targets = Variable(targets.long()).to(device) \n",
    "        targets = targets.squeeze(dim=1)\n",
    "        #targets = targets.type_as(outputs) #comment in the first try\n",
    "\n",
    "        inputs = inputs.permute(0,2,1,3,4)\n",
    "        outputs = model(inputs)\n",
    "        targets = targets.float()\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, targets)\n",
    "        #acc = calculate_accuracy(outputs, targets)\n",
    "\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        #accuracies.update(acc, inputs.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end_time)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print('Epoch: [{0}][{1}/{2}]\\t' #'Acc {acc.val:.3f} ({acc.avg:.3f})'\n",
    "              'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "              'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "              'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                  epoch,\n",
    "                  i + 1,\n",
    "                  len(loader),\n",
    "                  batch_time=batch_time,\n",
    "                  data_time=data_time,\n",
    "                  loss=losses))\n",
    "\n",
    "    save_file_path = os.path.join(save_model_path, 'save_{}.pth'.format(epoch))\n",
    "    states = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "    torch.save(states, save_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./save-model-3d/save_2.pth')['state_dict']\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/scratch/astamoulakatos/nsea_video_jpegs/'\n",
    "class_paths = [d.path for d in os.scandir(root_dir) if d.is_dir]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((576, 704)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class_names = ['exp_and','exp_fs','exp','exp_fj','bur']\n",
    "one_hot_classes = [[0,1,1,0,0],[0,1,0,0,1],[0,1,0,0,0],[0,1,0,1,0],[1,0,0,0,0]]\n",
    "\n",
    "df = pd.read_csv('./train-valid-splits-video/valid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_image_paths = []\n",
    "end_idx = []\n",
    "for c, class_path in enumerate(class_paths):\n",
    "    for d in os.scandir(class_path):\n",
    "        if d.is_dir:\n",
    "            if d.path in df.videos.values:\n",
    "                paths = sorted(glob.glob(os.path.join(d.path, '*.png')))\n",
    "                # Add class idx to paths\n",
    "                paths = [(p, one_hot_classes[c]) for p in paths]\n",
    "                class_image_paths.extend(paths)\n",
    "                end_idx.extend([len(paths)])\n",
    "                \n",
    "end_idx = [0, *end_idx]\n",
    "end_idx = torch.cumsum(torch.tensor(end_idx), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MySampler(end_idx, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(\n",
    "    image_paths=class_image_paths,\n",
    "    seq_length=seq_length,\n",
    "    transform=transform,\n",
    "    length=len(sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=bs,\n",
    "    sampler=sampler,\n",
    "    num_workers=0,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "all_y = []\n",
    "all_y_pred = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in valid_loader:\n",
    "        # distribute data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        X = X.permute(0,2,1,3,4)\n",
    "        y = y.squeeze(dim=1)\n",
    "        #y = y.type_as(output) # comment that line the first time and uncomment it after that\n",
    "        y = y.float()\n",
    "        output = model(X)\n",
    "        loss = F.binary_cross_entropy_with_logits(output, y)\n",
    "        test_loss += loss.item()   \n",
    "        # sum up batch loss\n",
    "        y_pred = output.sigmoid()\n",
    "        # collect all y and y_pred in all batches\n",
    "        all_y.extend(y)\n",
    "        all_y_pred.extend(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss /= len(valid_loader.dataset)\n",
    "\n",
    "# compute accuracy\n",
    "#all_y = torch.stack(all_y, dim=0)\n",
    "#all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "#test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "accuracy = ((all_y_pred>0.5).byte() == all_y.byte()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
