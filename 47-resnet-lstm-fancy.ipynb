{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_lstm import *\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "import sklearn\n",
    "plt.rcParams['figure.figsize'] = (20,8)\n",
    "font = {'family' : 'DejaVu Sans',  'weight' : 'normal',  'size'  : 20}\n",
    "plt.rc('font', **font)\n",
    "df_train = pd.read_csv('./train-valid-splits-video/train.csv')\n",
    "df_valid = pd.read_csv('./train-valid-splits-video/valid.csv')\n",
    "train_loader = load_data(df_train, 48, 16)\n",
    "valid_loader = load_data(df_valid, 48, 16)\n",
    "#cnn_encoder, rnn_decoder = load_model(bs=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1, ax1 = plt.subplots()\n",
    "# df_train.iloc[:,1:].sum(axis=0).plot.pie(autopct='%1.1f%%',shadow=True, startangle=90,ax=ax1)\n",
    "# ax1.axis(\"equal\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(df_train.iloc[:,1:].corr(), cmap=\"RdYlBu\", vmin=-1, vmax=1)\n",
    "# plt.show()\n",
    "# #correlation between labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(train_loader, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_encoder = ResCNNEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_pool = AdaptiveConcatPool2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_encoder.resnet[8] = adaptive_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in cnn_encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in cnn_encoder.resnet[8].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in cnn_encoder.headbn1.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in cnn_encoder.fc1.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_decoder = DecoderRNNattention(batch_size=48).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in rnn_decoder.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn_params, cnn_encoder, rnn_decoder = parallelize_model(cnn_encoder, rnn_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn_decoder.load_state_dict(torch.load('/media/scratch/astamoulakatos/save-model-lstm/rnn_decoder_epoch_freezed1.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_encoder.load_state_dict(torch.load('/media/scratch/astamoulakatos/save-model-lstm/cnn_encoder_epoch_freezed1.pth'),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "learning_rate = 0.01\n",
    "#optimizer =  torch.optim.SGD(crnn_params, lr=learning_rate, momentum=0.9, weight_decay=1e-3)\n",
    "epochs = 2\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(crnn_params, lr=learning_rate, momentum=0.9, weight_decay=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer.load_state_dict(torch.load('/media/scratch/astamoulakatos/save-model-lstm/optimizer_epoch_freezed1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = '/media/scratch/astamoulakatos/save-model-lstm/'\n",
    "for epoch in trange(epochs, desc=\"Epochs\"):    \n",
    "    cnn_encoder.train()\n",
    "    rnn_decoder.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0  \n",
    "    running_f1 = 0.0\n",
    "    train_result = []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        inputs, targets = inputs.to(device), targets.to(device) #.view(-1, )\n",
    "        targets = targets.squeeze(dim=1)\n",
    "        targets = targets.float()\n",
    "        #N_count += X.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn_decoder(cnn_encoder(inputs)) \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        preds = torch.sigmoid(outputs).data > 0.5\n",
    "        preds = preds.to(torch.float32)     \n",
    "        #step_score = pred_acc(y, output.sigmoid())\n",
    "        #scores.append(step_score) \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_acc += accuracy_score(targets.detach().cpu().numpy(), preds.cpu().detach().numpy()) *  inputs.size(0)\n",
    "        running_f1 += f1_score(targets.detach().cpu().numpy(), (preds.detach().cpu().numpy()), average=\"samples\")  *  inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_acc / len(train_loader.dataset)\n",
    "    epoch_f1 = running_f1 / len(train_loader.dataset)\n",
    "    \n",
    "    train_result.append('Training Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(epoch_loss, epoch_acc, epoch_f1))\n",
    "    print(train_result)\n",
    "    \n",
    "    cnn_encoder.eval()\n",
    "    rnn_decoder.eval()\n",
    "    valid_result = []\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0  \n",
    "    running_f1 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in valid_loader:\n",
    "            # distribute data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y = y.squeeze(dim=1)\n",
    "            y = y.float()\n",
    "            output = rnn_decoder(cnn_encoder(X))\n",
    "            loss = criterion(output, y)\n",
    "            running_loss += loss.item() * X.size(0)   \n",
    "            preds = torch.sigmoid(output).data > 0.5\n",
    "            preds = preds.to(torch.float32)  \n",
    "            running_acc += accuracy_score(y.detach().cpu().numpy(), preds.cpu().detach().numpy()) *  X.size(0)\n",
    "            running_f1 += f1_score(y.detach().cpu().numpy(), (preds.detach().cpu().numpy()), average=\"samples\")  *  X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "    epoch_acc = running_acc / len(valid_loader.dataset)\n",
    "    epoch_f1 = running_f1 / len(valid_loader.dataset)\n",
    "    valid_result.append('Validation Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(epoch_loss, epoch_acc, epoch_f1))\n",
    "    print(valid_result)\n",
    "    \n",
    "    torch.save(cnn_encoder.state_dict(), os.path.join(save_model_path, 'cnn_encoder_epoch_freezed_{}.pth'.format(epoch)))  # save spatial_encoder\n",
    "    torch.save(rnn_decoder.state_dict(), os.path.join(save_model_path, 'rnn_decoder_epoch_freezed_{}.pth'.format(epoch)))  # save motion_encoder\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch_freezed_{}.pth'.format(epoch)))      # save optimizer\n",
    "    print(\"Epoch {} model saved!\".format(epoch))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = torch.randn(2,10,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn1 = hn[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.randn(10,16,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_w = torch.bmm(out,hn1.unsqueeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
