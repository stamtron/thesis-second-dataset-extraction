{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_lstm import *\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train-valid-splits-video/train.csv')\n",
    "df_valid = pd.read_csv('./train-valid-splits-video/valid.csv')\n",
    "#train_loader = load_data(df_train, 32, 16)\n",
    "valid_loader = load_data(df_valid, 32, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "cnn_encoder = ResCNNEncoder().to(device)\n",
    "adaptive_pool = AdaptiveConcatPool2d()\n",
    "cnn_encoder.resnet[8] = adaptive_pool\n",
    "\n",
    "rnn_decoder = DecoderRNNattention(batch_size=48).to(device)\n",
    "\n",
    "crnn_params, cnn_encoder, rnn_decoder = parallelize_model(cnn_encoder, rnn_decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_decoder.load_state_dict(torch.load('/media/scratch/astamoulakatos/save-model-lstm/rnn_decoder_epoch_attention_freezed_5.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_encoder.load_state_dict(torch.load('/media/scratch/astamoulakatos/save-model-lstm/cnn_encoder_epoch_attention_5.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_decoder.eval()\n",
    "cnn_encoder.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for X, y in valid_loader:\n",
    "        X, y = X.to(device), y.to(device).view(-1, )\n",
    "        output = rnn_decoder(cnn_encoder(X))\n",
    "        X = X.to(device)\n",
    "        y = Variable(y.float()).to(device) \n",
    "        X = X.permute(0,2,1,3,4)\n",
    "        y = y.squeeze(dim=1)\n",
    "        y = y.float()\n",
    "        output = model(X)\n",
    "        y = y.detach().cpu()\n",
    "        #loss = criterion(output, y)\n",
    "        preds = torch.sigmoid(output)\n",
    "        preds = preds.to(torch.float32) s\n",
    "        preds = preds.detach().cpu()\n",
    "        y_pred.append(preds)\n",
    "        y_true.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.vstack([t.__array__() for tensor in y_true for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pr = np.vstack([t.__array__() for tensor in y_pred for t in tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = nsea_compute_thresholds(y_tr, y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_tr, y_pr)\n",
    "f1 = f1_score(y_tr, y_pr, average=\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compute_metrics(y_tr, y_pr, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
